【TOC]

## 硬件基础

### 软中断

#### 中断是什么？

- 中断是系统⽤来响应硬件设备请求的⼀种机制，操作系统收到硬件的中断请求，会打断正在执⾏的进程，然后调⽤内核中的中断处理程序来响应请求；
- 中断是⼀种 **异步事件处理机制**，可以提⾼系统的并发处理能⼒；

#### 什么是软中断？

- 中断请求的处理程序应该要短且快，这样才能减少对正常进程运⾏调度地影响，⽽且中断处理程序可能会暂时关闭中断，这时如果中断处理程序执⾏时间过⻓，可能在还未执⾏完中断处理程序前，会丢失当前其他设备的中断请求；
- Linux 系统 **为了解决中断处理程序执⾏过⻓和中断丢失的问题**，将中断过程分成了两个阶段：
  - **上半部⽤来快速处理中断**，⼀般会暂时关闭中断请求，主要负责处理跟硬件紧密相关或者时间敏感的事情；
  - **下半部⽤来延迟处理上半部未完成的⼯作**，⼀般以「内核线程」的⽅式运⾏。
- 所以，中断处理程序的上部分和下半部可以理解为：
  - **上半部直接处理硬件请求，也就是硬中断**，主要是负责耗时短的⼯作，特点是快速执⾏；
  - **下半部是由内核触发，也就说软中断**，主要是负责上半部未完成的⼯作，通常都是耗时⽐较⻓的事情，特点是延迟执⾏；
- 硬中断（上半部）是会打断 CPU 正在执⾏的任务，然后⽴即执⾏中断处理程序，⽽软中断（下半部）是以内核线程的⽅式执⾏，并且每⼀个 CPU 都对应⼀个软中断内核线程
- Linux 中的软中断包括⽹络收发、定时、调度、 RCU 锁等各种类型

### 为什么 $0.1+0.2\neq0.3$

#### 为什么负数用补码表示？

- 如果负数不是使用补码，则在做基本的加减法运算时，还需要 **多一步操作来判断是否为负数，如果为负数，需要把加法反转成减法，或者把减法反转成加法**；
- 用了补码的表示方式后，对于负数的加减法操作，实际上和正数加减法操作是一样的；

- 负数之所以⽤补码的⽅式来表示，主要是为了统⼀和正数的加减法操作⼀样。

#### 十进制转换为二进制

⼗进制整数转⼆进制使⽤的是 **除 2 取余法**，⼗进制⼩数使⽤的是 **乘 2 取整法**。

以 `8.625` 为例，转化过程如下图所示：

![十进制转二进制.PNG](https://i.loli.net/2021/08/07/epza8jSk3yQNR1u.png)

并不是所有的小数都可以用二进制表示，`0.1` 的二进制表示是无线循环的。

由于计算机的资源是有限的，所以是没办法⽤⼆进制精确的表示 0.1，只能⽤ **近似值** 来表示，就是在有限的精度情况下，最⼤化接近 0.1 的⼆进制数，于是就会造成精度缺失的情况。

对于⼆进制⼩数转⼗进制时，需要注意⼀点，⼩数点后⾯的指数幂是 **负数**。

举个例子，二进制 `1010.101` 转换为十进制的过程如下图：

![二进制转十进制.PNG](https://i.loli.net/2021/08/07/vEDFB8ORa5d3NQw.png)



#### 计算机存小数

计算机是以浮点数的形式存储⼩数的，⼤多数计算机都是 IEEE 754 标准定义的浮点数格式，包含三个部分：

- 符号位：为 0 表示正数，为 1 表示负数；
- 指数位：指定了⼩数点在数据中的位置，指数可以是负数，也可以是正数，指数位的⻓度越⻓则数值的表达范围就越⼤；
- 尾数位：⼩数点右侧的数字，也就是⼩数部分，⽐如⼆进制 $1.0011 * 2^{-2}$​，尾数部分就是 0011，⽽且尾数的⻓度决定了这个数的精度，因此如果要表示精度更⾼的⼩数，则就要提⾼尾数位的⻓度；

小数 `10.625` 在计算机中以 float 型的存储形式为：

![计算机存小数.PNG](https://i.loli.net/2021/08/07/sSjwnGka3bUK1vY.png)

- 把小数点 **移动到第一个有效数字后面**，小数点左移，就在指数位 **127 + 移动位数**；反之，小数点右移，就在指数位 **127 - 移动位数**；

把 float 型数据转换成十进制的过程如下图所示：

![float转十进制.PNG](https://i.loli.net/2021/08/07/JuKrpPI1nAMxs5t.png)

## 操作系统结构

### 内核

#### Linux vs Windows

- Linux 内核架构是 **宏内核**，即 Linux 的内核是一个完整的可执行程序，拥有最高的权限；
- 宏内核的特征是 **系统内核的所有模块**，⽐如进程调度、内存管理、⽂件系统、设备驱动等，**都运⾏在内核态**；
- **微内核** 与宏内核相反，其只保留最基本的能⼒，⽐如进程调度、虚拟机内存、中断等，把⼀些应⽤放到了⽤户空间，⽐如驱动程序、⽂件系统等。这样服务与服务之间是隔离的，单个服务出现故障或者完全攻击，也不会导致整个操作系统挂掉，提⾼了操作系统的稳定性和可靠性；
- 微内核架构的系统内核功能少，可移植性⾼，相⽐宏内核有⼀点不好的地⽅在于，由于驱动程序不在内核中，⽽且驱动程序⼀般会频繁调⽤底层能⼒的，于是驱动和硬件设备交互就需要频繁切换到内核态，这样会带来性能损耗。

#### 什么是内核

- 应用程序连接硬件设备的桥梁；应用程序只需关心与内核交互，不用关心硬件的细节

#### 内核的基本功能

- **管理进程、线程**，决定哪个进程、线程使用CPU，也就是**进程调度**的能力

- **管理内存**，决定内存的分配和回收，也就是**内存管理**的能力
- **管理硬件设备**，为进程与硬件设备之间提供通信能力，也就是**硬件通信**的能力
- 提供**系统调用**，如果应用程序要运行更高权限运行的服务，那么就需要有系统调用，它是用户程序与操作系统之间的接口

#### 内核如何工作

内核具有很高的权限，可以控制 cpu、内存、硬盘等硬件，而应用程序具有的权限很小，因此大多数操作系统，把内存分成了两个区域：

- 内核空间，只有内核程序可以访问；
- 用户空间，专门给应用程序使用；

⽤户空间的代码只能访问⼀个局部的内存空间，⽽内核空间的代码可以访问所有内存空间。因此，当程序使用用户空间时，我们常说该程序在**用户态**执行，而当程序使用内核空间时，程序则在**内核态**执行。

应⽤程序如果需要进入内核空间，就需要通过**系统调用**，系统调用的过程：

> 内核程序执行在内核态，用户程序执行在用户态。当应用程序使用系统调用时，会产生一个中断。发生中断后，CPU会中断当前在执行的用户程序，转而跳转到中断处理程序，也就是开始执行内核程序。内核处理完后，主动触发中断，把CPU执行权限交回给用户程序，回到用户态继续工作。

系统调用将Linux整个体系分为用户态和内核态（或者说内核空间和用户空间）；

用户态就是提供应用程序运行的空间，为了使应用程序访问到内核管理的资源例如CPU、内存、I/O。内核必须提供一组通用的访问接口，这些接口就叫 **系统调用**。

**库函数** 用于屏蔽复杂的底层实现细节，减轻程序员的负担，从而更加关注上层的逻辑实现。它对系统调用进行封装，提供简单的基本接口给用户，这样增强了程序的灵活性。

从用户态到内核态切换可以通过三种方式：

- 系统调用：系统调用本身就是中断，但是软件中断，跟硬中断不同
- 异常：如果当前进程运行在用户态，如果这个时候发生了异常事件，就会触发切换。例如：缺页异常。
- 外设中断：当外设完成用户的请求时，会向CPU发送中断信号。

## 内存管理

### 虚拟内存

- 虚拟存储技术的基本思想时利用大容量外存来扩充内存，产生一个比有限的实际内存空间大得多的、逻辑的虚拟空间，简称虚存，以便能够有效地支持多道程序系统的实现和大型程序运行的需要，从而增强系统的处理能力；

多进程环境下，让操作系统为每个进程分配独立的一套**虚拟地址**，把进程所使用的地址「隔离」开来，使得进程之间的内存地址互不影响。**即将不同进程的虚拟地址和不同内存的物理地址映射起来**。如果程序要访问虚拟地址的时候，有操作系统转换成不同的物理地址，这样不同的进程运行的时候，写入的是不同的物理地址，就不会冲突了。于是，引出了两种地址的概念：

- 用户程序所使用的内存地址叫做 **虚拟内存地址**
- 实际存在硬件里的空间地址叫做 **物理内存地址**

进程持有的虚拟内存地址会通过 CPU 芯片中的内存管理单元的映射关系，转换变成物理地址，然后再通过物理地址访问内存。

- 操作系统如何管理虚拟地址与物理地址之间的关系：内存分段，内存分页

#### 虚拟内存作用

- 内存保护，保护了每个进程的地址空间不被其他进程破坏；
- 内存管理，为每个进程提供了一致的地址空间，简化内存管理；
- 将主存看做一个存储在磁盘空间上的地址空间的高速缓存，在主存中只保存活动区域，并根据需要在磁盘和主存之间来回传送数据；
- 善用碎片空间，更有效率地使用主存。能够创建给主存更多的空间，每个进程都独有一个虚拟内存，并且解决主存非连续空间分配内存给某进程。

### 内存分段

程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段有不同的属性，所以就用分段的形式把这些段分离出来。

#### 分段机制下，虚拟地址和物理地址如何映射？

分段机制下的虚拟地址由两部分组成，**段选择子** 和 **段内偏移量**。

![捕获.PNG](https://i.loli.net/2021/08/02/sxi16py8HzelI2q.png)

- **段选择子** 保存在段寄存器里面。段选择子里面最重要的是 **段号**，用作段表的索引。**段表** 里面保存的是这个段的 **基地址**、**段界限** 和 特权等级等。
- 虚拟地址中的 **段内偏移量** 应该位于0和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到 **物理内存地址**。

虚拟地址是通过 **段表** 与物理地址进行映射的，分段机制会把程序分成4个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，就能找到物理内存中的地址，如下图：

![段寻址.PNG](https://i.loli.net/2021/08/02/UYZMwTlikShOj8L.png)

分段方法的不足：

- **内存碎片** 的问题
- **内存交换效率低** 的问题

#### 为什么会产生内存碎片？

假设有$1G$ 的物理内存，用户执行了多个程序，其中：

- 游戏占用了 $512MB$ 内存
- 浏览器占用了 $128MB$ 内存
- 音乐占用了 $256MB$ 内存

如果我们这时关闭了浏览器，则空闲内存还有 $256MB$。如果这个 $256MB$ 不是连续的，被分成了两段 $128MB$ 内存，就会导致没有空间再打开一个 $200MB$ 的程序。

这里的内存碎片问题共有两处地方：

- **外部内存碎片**，也就是产生了 **多个不连续的小物理内存**，导致新的程序无法被装载；
- **内部内存碎片**，程序所有的内存都被装载到了物理内存，但是这个 **程序有部分的内存并不是很常被使用**，这也会导致内存的浪费；

解决外部内存碎片的问题就是 **内存交换**。先把某些程序占用的内存写到硬盘上，然后再从硬盘上读回到内存里。

#### 为什么会导致内存交换效率低？

用分段方式，内存碎片是很容易产生的，产生了内存碎片，就不得不重新 **Swap** 内存区域，这个过程会产生性能瓶颈。

因为硬盘的访问速度要比内存满太多，而每一次内存交换，都需要把一大段的内存数据写到硬盘上。

### 内存分页

**内存分页** 能解决内存碎片和内存交换空间太大的问题。

**分页就是把整个虚拟和物理内存空间切成一段段固定尺寸的大小**。这样一个连续并且尺寸固定的内存空间，叫做 **页**。在Linux下，每一页的大小为 $4KB$。

虚拟地址与物理地址之间通过 **页表** 来映射，如下图：

![内存分页.PNG](https://i.loli.net/2021/08/03/STvewDML517NZEG.png)

页表是存储在内存里的，**内存管理单元（MMU）** 负责将虚拟地址转换成物理地址。

当进程访问的虚拟地址在页表中查不到时，系统会产生一个 **缺页异常**，进入系统内核空间分配物理内存、更新进程页表，最后再返回用户空间，恢复进程的运行。

#### 分页是怎么解决分段的内存碎片、内存交换效率低的问题？

由于内存空间都是预先划分好的，也就不会产生间隙非常小的内存。而采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。

如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，成为 **换出**。一旦需要的时候，再加载进来，称为 **换入**。所以，一次性写入磁盘的只有少数的一个页或几个页，不会花太多时间，**内存交换的效率就相对比较高**。

![换入换出.PNG](https://i.loli.net/2021/08/03/tYPi7ZIhFCkbmzp.png)

更进一步的，分页的方式使得我们在加载程序的时候，**不再需要一次性地把程序都加载到物理内存中**。完全可以在进行虚拟内存和物理内存的页之间的映射之后，并不真的把页加载到物理内存里，而是**只有在程序运行中，需要用到对应虚拟内存里面的指令和数据时，再加载到物理内存里面去**。

#### 虚拟地址和物理地址如何映射？

分页机制下，虚拟地址分为两部分，**页号**和**页内偏移量**。页号作为页表的索引，页表包含物理页每页所在**物理内存的基地址**，这个基地址与页内偏移的组合就形成了物理内存地址，见下图：

![页表映射.PNG](https://i.loli.net/2021/08/03/sxretFfouBIbJV3.png)

对于一个内存地址转换，包括三个步骤：

- 把虚拟内存地址，切分成页号和偏移量；
- 根据页号，从页表里面，查询对应的物理页号；
- 直接拿物理页号，加上前面的偏移量，就得到了物理内存地址。

#### 简单分页有什么缺陷？

在32位的环境下，虚拟地址空间共有 $4GB$​，假设一个页的大小是 $4KB(2^{12})$​，那么就需要大约100万个$(2^{20})$页，每个「页表项」需要 4 个字节大小来存储，那么整个 $4GB$ 空间的映射就需要有 $4MB$​ 的内存来存储页表。

这 $4MB$ 大小的页表，看起来不大，但是每个进程都有自己的虚拟地址空间，也就是说都有自己的页表。那么，100个进程的话，就需要 $400MB$ 的内存来存储页表。

### 多级页表

把100多万个「页表项」的单级页表再分页，把页表（一级页表）分为 **1024** 个页表（二级页表），每个二级页表中包含 **1024** 个「页表项」，形成**二级分页**。如下图：

![多级页表.PNG](https://i.loli.net/2021/08/03/sEMTBDeiy5hZRwX.png)

如果使用了二级分页，⼀级页表就可以覆盖整个 $4GB$​ 虚拟地址空间，但 **如果某个一级页表的页表项没有被用到，也就不需要创建这个页表项对应的二级页表了，即可以在需要时才创建二级页表**。做个简单计算，假设只有 $20\%$ 的一级页表项被用到了，那么页表占用的内存空间就只有 $4KB + 20\% * 4MB = 0.804MB$。

那么为什么不分级的页表就做不到这样节约内存呢？我们从页表的性质来看，保存在内存中的页表承担的 职责是将虚拟地址翻译成物理地址。假如虚拟地址在页表中找不到对应的页表项，计算机系统就不能工作了。所以 **页表一定要覆盖全部虚拟地址空间，不分级的页表就需要有 100 多万个页表项来映射，而二级分页则只需要 1024 个页表项**（此时一级页表覆盖到了全部虚拟地址空间，⼆级页表在需要时创建）。

对于64位系统，两级分页不够，需要四级目录，分别是：

- 全局页目录项 **PGD**
- 上层页目录项 **PUD**
- 中间页目录项 **PMD**
- 页表项 **PTE**

![四级目录.PNG](https://i.loli.net/2021/08/03/UsAqlc86BTrvVF1.png)

### TLB

多级页表虽然解决了空间上的问题，但是虚拟地址到物理地址的转换就多了几道转换的⼯序，这显然就降低了这俩地址转换的速度，也就是带来了时间上的开销。
而程序是有 **局部性** 的，即在⼀段时间内，整个程序的执行仅限于程序中的某⼀部分。相应地，执行所访问的存储空间也局限于某个内存区域。

我们就可以利用这⼀特性，把 **最常访问的几个页表项** 存储到访问速度更快的硬件，于是在 CPU 芯片中，加入了⼀个专门存放程序最常访问的页表项的 **Cache**，这个 Cache 就是**TLB**，通常称为页表缓存，转址旁路缓存、快表等。

![TLB.PNG](https://i.loli.net/2021/08/03/FaqJeRkznQomA4j.png)

在 CPU 芯片中，封装了内存管理单元 **MMU** 芯片，用来完成地址转换和 **TLB** 的访问和交互。

有了 **TLB** 后，那么 CPU 在寻址时，会先查 **TLB**，如果没找到，才会继续查常规的页表。

### 段页式内存管理

段页式内存管理实现的方式：

- 先将程序划分为多个有逻辑意义的段
- 接再把每个段划分为多个页

这样，地址结构就由 **段号、段内页号和页内偏移** 三部分组成。

![段页式内存管理.PNG](https://i.loli.net/2021/08/13/2zGv38WHlaXxYq7.png)

段页式地址变换中要得到物理地址须经过 **三次内存访问**：

- 第一次 **访问段表**，得到页表起始地址；
- 第二次 **访问页表**，得到物理页号；
- 第三次将物理页号与页内偏移组合，得到物理地址。

### 页面置换算法

当 CPU 访问的⻚⾯不在物理内存时，便会产⽣⼀个 **缺⻚中断**，请求操作系统将所缺⻚调⼊到物理内存。那它与⼀般中断的主要区别在于：

- 缺页中断在指令执行期间产生和处理中断信号，而一般中断在一条指令执行完成后检查和处理中断信号；
- 缺页中断返回到该指令的开始 **重新执行该指令**，而一般中断返回到该指令的 **下一条指令执行**。

缺页中断处理流程：

<img src="https://i.loli.net/2021/08/07/1lFmZpwYnThexS9.png" alt="缺页中断.PNG" style="zoom: 80%;" />

1. 在 CPU 里访问一条 `Load M` 指令，然后 CPU 会去找 M 指令所对应的表项；
2. 如果该页表项的状态位是 **有效的**，那 CPU 就可以直接去访问物理内存了，如果状态位是 **无效的**，则 CPU 会发送缺页中断请求；
3. 操作系统收到了缺页中断，则会执行缺页中断处理函数，先去查找页面在磁盘中的页面的位置；
4. 找到磁盘中对应的页面后，需要把页面换入到物理内存中，但是在换入前，需要在物理内存中找空闲页；
5. 页面从磁盘换入到物理内存后，把页表项中的状态位修改为有效的；
6. 最后，CPU 重新执行导致缺页中断的指令。

如果第 4 步找不到空闲页，则说明此时内存已满了。需要 **页面置换算法** 选择一个物理页，如果该物理页有被修改过，则把它换出到磁盘，然后把该被置换出去的页表项的状态修改为 **无效的**。

页表项通常有如下字段：

![页表项.PNG](https://i.loli.net/2021/08/07/FTEBwxlgp1VqbNL.png)

其中：

- 状态位：用于表示该页面 **是否有效**，也就是说是否在物理内存中；
- 访问字段：用于记录该页在一段时间被访问的次数，供页面置换算法选择换出页面时参考；
- 修改位：表示该⻚在调⼊内存后是否有被修改过，由于内存中的每⼀⻚都在磁盘上保留⼀份副本，因此，如果没有修改，在置换该⻚时就不需要将该⻚写回到磁盘上，以减少系统的开销；如果已经被修改，则将该⻚重写到磁盘上，以保证磁盘中所保留的始终是最新的副本。
- 硬盘地址：用于指出该页在硬盘上的地址，通常是物理块号。

虚拟内存管理流程如下图所示：

<img src="https://i.loli.net/2021/08/07/m1w4XNbUFQ73eBR.png" alt="虚拟内存管理.png" style="zoom: 67%;" />

⻚⾯置换算法的功能是：当出现缺⻚异常，需调⼊新⻚⾯⽽内存已满时，选择被置换的物理⻚⾯，也就是说选择⼀个物理⻚⾯换出到磁盘，然后把需要访问的⻚⾯换⼊到物理⻚。

那其算法⽬标则是，尽可能 **减少⻚⾯的换⼊换出的次数**。

#### 最佳页面置换算法

最佳页面置换算法的基本思想是：置换在 **未来最长时间不访问的页面**。

该算法实现需要计算内存中每个逻辑⻚⾯的「下⼀次」访问时间，然后⽐较，选择未来最⻓时间不访问的⻚⾯。

举个例子，假设一开始有 3 个空闲的物理页，然后有请求的页面序列，那它的置换过程如下图：

![最佳页面置换算法.PNG](https://i.loli.net/2021/08/07/W2AzMjwFidkQVUX.png)

这个置换算法很理想，在实际系统中⽆法实现，因为程序访问⻚⾯时是动态的，⽆法预知每个⻚⾯在「下⼀次」访问前的等待时间。

所以，最佳⻚⾯置换算法作⽤是为了衡量你的算法的效率，你的算法效率越接近该算法的效率，那么说明
你的算法是⾼效的。

#### 先进先出页面置换算法

先进先出页面置换算法的基本思想是：置换在 **内存驻留时间很⻓的⻚⾯**。

以前⾯的请求的⻚⾯序列作为例⼦，先进先出页面置换算法工作过程如下图：

![先进先出页面置换算法.PNG](https://i.loli.net/2021/08/07/sd1joAJUrmMBN8b.png)

在这个请求的⻚⾯序列中，缺⻚共发⽣了 10 次，⻚⾯置换共发⽣了 7 次，跟最佳⻚⾯置换算法⽐较起来，性能明显差了很多。

#### 最近最久未使用页面置换算法

最近最久未使⽤（LRU）页面置换算法的基本思想是：置换 **最长时间没有被访问的页面**。

以前⾯的请求的⻚⾯序列作为例⼦，最近最久未使用页面置换算法工作过程如下图：

![最近最久未使用页面置换算法.PNG](https://i.loli.net/2021/08/07/BsWQLjliv7uKwXo.png)

在这个请求的⻚⾯序列中，缺⻚共发⽣了 9 次，⻚⾯置换共发⽣了 6 次，跟先进先出置换算法⽐较起来，性能提⾼了⼀些。

虽然 LRU 在理论上是可以实现的，但代价很⾼。为了完全实现 LRU，需要在 **内存中维护⼀个所有⻚⾯的链表**，最近最多使⽤的⻚⾯在表头，最近最少使⽤的⻚⾯在表尾。

在每次访问内存时都必须要更新「整个链表」。在链表中找到⼀个⻚⾯，删除它，然后把它移动到表头是⼀个⾮常费时的操作

#### 时钟页面置换算法

时钟页面置换算的基本思想是：把所有的⻚⾯都保存在⼀个类似钟⾯的 **环形链表** 中，⼀个表针指向最⽼的⻚⾯。

当发生缺页中断时，算法首先检查表针指向的页面：

- 如果它的访问位是 0 ，就淘汰该页面，并把新的页面插入到这个位置，然后把表针前移一个位置；
- 如果访问位是 1，就清除访问位，并把表针前移一个位置，重复这个过程直到找到一个访问位位 0 的页面为止。

时钟页面置换算法的工作流程图如下：

<img src="https://i.loli.net/2021/08/07/QD3MA6Vdlapshu9.png" alt="时钟页面置换算法流程.PNG" style="zoom:80%;" />

#### 最不常用页面置换算法

该算法基本思想是：当发⽣缺⻚中断时，置换 **访问次数最少的⻚⾯**。

它的实现⽅式是，对每个⻚⾯设置⼀个 **访问计数器**，每当⼀个⻚⾯被访问时，该⻚⾯的访问计数器就累加 1。在发⽣缺⻚中断时，**淘汰计数器值最⼩的那个⻚⾯**。

## 进程与线程

### 进程

我们编写的代码只是⼀个存储在硬盘的静态文件，通过编译后就会生成二进制可执行文件，当我们运行这个可执行文件后，它会被装载到内存中，接着 CPU 会执行程序中的每⼀条指令，那么这个 **运行中的程序，就被称为「进程」（Process）**。

#### 并行与并发

- 并发：在某个瞬间，只能运行一个进程；但在一段时间内，比如 1 秒钟期间，运行多个进程；

![并发与并行.PNG](https://i.loli.net/2021/08/03/MBK4fRGby13U2li.png)

#### 进程的状态

进程有着「运行 - 暂停 - 运行」的活动规律。⼀般说来，⼀个进程并不是自始至终连续不停地运行的，它与并发执行中的其他进程的执行是相互制约的。

它有时处于运行状态，有时⼜由于某种原因而暂停运行处于等待状态，当使它暂停的原因消失后，它又进入准备运行状态。

所以，一个进程的活动期间至少具备三种基本状态：**运行状态**、**就绪状态**、**阻塞状态**。

- 运行状态：该时刻进程占用 CPU
- 就绪状态：可运行，由于其他进程处于运行状态而暂时停止运行
- 阻塞状态：该进程正在等待某一事件发生（如等待输入/输出操作的完成）而暂时停止运行，这时，即使给它CPU控制权，它也无法运行。

一个完整的进程状态转移图如下：

![进程状态转移.PNG](https://i.loli.net/2021/08/03/4CsxnJG9dvPpH5m.png)

- 运行状态 ——>就绪状态：分配给该进程的 **运行时间片用完**

如果有大量处于阻塞状态的进程，进程可能会占用着物理内存空间。所以，在虚拟内存管理的操作系统中，通常会把阻塞状态的进程的物理内存空间换出到硬盘，等需要再次运行的时候，再从硬盘换如到物理内存

那么，就需要⼀个新的状态，来 **描述进程没有占用实际的物理内存空间的情况**，这个状态就是 **挂起状态**。

- 阻塞挂起状态：进程在外存并等待某个事件（请求 I/O）的出现
- 就绪挂起状态：进程在外存，但只要进入内存，就能立即运行
- **就绪 ---> 就绪挂起**：操作系统一般是挂起阻塞进程，但有时也会挂起就绪进程，以释放足够的内存空间；
- **就绪挂起 ---> 就绪**：当内存中没有就绪态进程，或者就绪挂起态进程具有比就绪态进程更高的优先级，系统将把就绪挂起态进程转换成就绪态；
- **阻塞挂起 ---> 阻塞**：当一个进程等待一个事件时，原则上不需要把它调入内存。但是在下面一种情况下，这一状态变化是可能的。当一个进程退出后，主存已经有了一大块自由空间，而某个阻塞挂起态进程具有较高的优先级并且操作系统已经得知导致它阻塞的事件即将结束，此时便发生了这一状态变化；
- **运行态 ---> 就绪挂起**：当一个具有 **较高优先级** 的阻塞挂起态进程的等待事件结束后，它需要 **抢占 CPU**，而此时主存空间不够，从而可能导致正在运行的进程转化为就绪挂起态。另外处于运行态的进程也可以自己挂起自己；
- **新建 ---> 就绪挂起**：考虑到系统当前资源状况和性能要求，可以决定新建的进程将被对换出去成为就绪挂起态。

这两种挂起状态加上前面的五种状态，就变成了七种状态转移：

![挂起状态.PNG](https://i.loli.net/2021/08/03/YpAwtQhKLe2Bu6W.png)

导致进程挂起的原因不只是因为进程所使用的内存空间不在物理内存，还包括如下情况：

- 通过 sleep 让进程间歇性挂起，其⼯作原理是设置⼀个定时器，到期后唤醒进程；
- 用户希望挂起⼀个程序的执行，比如在 Linux 中用 **Ctrl+Z** 挂起进程

#### 进程的控制结构

在操作系统中，是用 **进程控制块（process control block，PCB）** 数据结构来描述进程的。

***PCB是进程存在的唯⼀标识***，这意味着⼀个进程的存在，必然会有⼀个 PCB，如果进程消失了，那么PCB 也会随之消失。

##### PCB包含信息

- 进程描述信息：
  - 进程标识符
  - 用户标识符
- 进程控制和管理信息
  - 进程当前状态
  - 进程优先级：进程抢占 CPU 时的优先级
- 资源分配清单
  - 有关内存地址空间或虚拟地址空间的信息，所打开文件的列表和所使用的 I/O 设备信息
- CPU相关信息
  - CPU 中各个寄存器的值，当进程被切换时，CPU 的状态信息都会被保存在相应的PCB 中，以便进程重新执行时，能从断点处继续执行。

##### PCB 是如何组织的？

通常是通过 **链表** 的方式进行组织，把具有 **相同状态的进程链在一起，组成各种队列**。比如：

- 将所有处于就绪状态的进程链在一起，称为**就绪队列**；
- 把所有因等待某事件而处于等待状态的进程链在一起，组成**阻塞队列**；
- 另外，对于运行队列，在单核CPU系统中只有一个运行指针。

除了链表的组织方式，还有索引方式：将同一状态的进程组织在一个索引表中。

一般会选择链表，因为可能面临进程创建，销毁等调度导致进程状态发生变化，所以链表能够更加灵活的插入和删除。

#### 进程的控制

##### 创建进程

操作系统允许一个进程创建另一个进程，而且允许子进程继承父进程所拥有的资源，当子进程被终止时，其在父进程处所继承的资源应当还给父进程。同时，终止父进程会终止其所有的子进程。

创建进程的过程如下：

- 为新进程分配一个唯一的进程标识号，并申请一个空白的 PCB, PCB 是有限的，若申请失败则创建失败；
- 为进程分配资源，此处如果资源不足，进程就会进入等待状态，以等待资源；
- 初始化 PCB；
- 如果进程的调度队列能够接纳新进程，那就将进程插入到就绪队列，等待被调度运行。

##### 终止进程

进程可以有三种终止方式：正常、异常以及 外界干预（信号 **kill** 掉）

终止进程的过程如下：

- 查找需要终止的进程的 PCB
- 如果处于执行状态，则立即终止该进程的运行，然后将 CPU 资源分配给其他进程；
- 如果还有子进程，则应将其所有子进程终止；
- 将该进程所拥有的全部资源都归还给父进程或操作系统
- 将其从 PCB 所在队列中删除；

##### 阻塞进程

当进程需要等待某⼀事件完成时，它可以调⽤阻塞语句把⾃⼰阻塞等待。⽽⼀旦被阻塞等待，它只能由另⼀个进程唤醒。

阻塞进程的过程如下：

- 查找将要被阻塞的进程的 PCB
- 如果该进程为运行状态，则保护其现场，将其状态转为阻塞状态，停止运行
- 将该 PCB 插入到阻塞队列中去

##### 唤醒进程

进程由「运⾏」转变为「阻塞」状态是由于进程必须等待某⼀事件的完成，所以处于阻塞状态的进程是不可能叫醒⾃⼰的。

如果某进程正在等待 I/O 事件，需由别的进程发消息给它，则只有当该进程所期待的事件出现时，才由发现者进程⽤唤醒语句叫醒它

唤醒进程的过程如下：

- 在该事件的阻塞队列中找到相应进程的 PCB
- 将其从阻塞队列中移除，并置其状态为就绪状态；
- 将该 PCB 插入到就绪队列中，等待调度程序调度。

#### 进程的上下文切换

各个进程之间是共享 CPU 资源的，在不同的时候进程之间需要切换，让不同的进程可以在 CPU 执行，那么这个 **⼀个进程切换到另⼀个进程运⾏**，称为进程的上下文切换。

##### CPU 上下文切换

任务是交给 CPU 运行的，那么在每个任务运行前，CPU 需要知道任务从哪里加载，又从哪里开始运行。

所以，操作系统需要事先帮 CPU 设置好 **CPU寄存器和程序计数器**

CPU 寄存器是 CPU 内部⼀个容量小，但是速度极快的内存（缓存）。程序计数器则用来存储 CPU 正在执⾏的指令位置、或者即将执⾏的下⼀条指令位置。

CPU 寄存器和程序计数器里存放的是 CPU 在运⾏任何任务前，所必须依赖的环境，这些环境就叫做 **CPU上下文**。

**CPU 上下⽂切换** 就是先把前⼀个任务的 CPU 上下⽂（CPU 寄存器和程序计数器）保存起来，然后加载新任务的上下⽂到这些寄存器和程序计数器，最后再跳转到程序计数器所指的新位置，运⾏新任务。

**系统内核会存储保持下来的上下⽂信息**，当此任务再次被分配给 CPU 运⾏时，CPU 会重新加载这些上下文，这样就能保证任务原来的状态不受影响，让任务看起来还是连续运⾏。

上面说到所谓的「任务」，主要包含进程、线程和中断。所以，可以根据任务的不同，把 CPU 上下⽂切换分成：**进程上下⽂切换**、**线程上下⽂切换**和**中断上下⽂切换**。

##### 进程的上下文切换

进程是由内核管理和调度的，所以 **进程的切换只能发⽣在内核态**。

进程的上下文切换**不仅包含了虚拟内存、栈、全局变量等⽤户空间的资源，还包括了内核堆栈、寄存器等内核空间的资源**。

通常，会把交换的信息保存在进程的 PCB，当要运⾏另外⼀个进程的时候，我们需要从这个进程的 PCB 取出上下文，然后恢复到 CPU 中，这使得这个进程可以继续执⾏，如下图所示：

![进程的上下文切换.PNG](https://i.loli.net/2021/08/03/q9ZjNm5ebzF2Ycs.png)

##### 进程的上下文切换发生场景

- 为了保证所有进程可以得到公平调度，CPU 时间被划分为⼀段段的时间片，这些时间片再被轮流分配给各个进程。这样，当某个进程的 **时间片耗尽** 了，进程就从运行状态变为就绪状态，系统从就绪队列选择另外⼀个进程运⾏；
- 进程在 **系统资源不⾜**（⽐如内存不⾜）时，要等到资源满⾜后才可以运⾏，这个时候进程也会被挂起，并由系统调度其他进程运⾏；
- 当进程通过 **睡眠函数 sleep** 这样的⽅法将⾃⼰主动挂起时，⾃然也会重新调度；
- 当有 **优先级更⾼的进程**运⾏时，为了保证⾼优先级进程的运⾏，当前进程会被挂起，由⾼优先级进程来运⾏；
- 发⽣ **硬件中断** 时，CPU 上的进程会被中断挂起，转而执行内核中的中断服务程序。

### 线程

#### 什么是线程

线程是**进程当中的一条执行流程**。

同⼀个进程内多个线程之间可以共享代码段、数据段、打开的文件等资源，但每个线程各自都有⼀套独立的寄存器和栈，这样可以确保线程的控制流是相对独立的。

#### 线程的优缺点

优点：

- 一个进程中可以同时存在多个线程
- 各个线程之间可以并发执行
- 各个线程之间可以共享地址空间和文件等资源

缺点：

- 当进程中的一个线程崩溃时，会导致其所属进程的所有线程崩溃

#### 线程与进程的比较

比较如下：

- 进程是资源（包括内存、打开的文件等）分配的单位，线程是 CPU 调度的单位；
- 进程拥有一个完整的资源平台，而线程只独享必不可少的资源，如寄存器和栈；
- 线程同样具有就绪、阻塞、执行三种基本状态，同样具有状态间的转换；
- 线程能减少并发执行的时间和空间开销；

线程相比进程能减少开销：

- 线程的创建时间比进程快，因为进程创建时，需要资源管理信息，线程则是共享这些信息；
- 线程的终止时间比进程快，因为其释放的资源相比进程少很多；
- 同一个进程内的线程切换比进程间切换快，因为线程具有相同的地址空间（虚拟内存共享），这意味着同一个进程的线程间具有同一个页表，所以在切换的时候不需要切换页表。而进程间的切换需要切换页表，这个过程开销较大；
- 同一进程的各线程间共享内存和文件资源，因此在线程间传递数据的时候，就不需要经过内核，数据交互效率更高；

#### 线程的上下文切换

线程与进程的最大区别在于：**线程是调度的基本单位，而进程则是资源拥有的基本单位**。

因此，操作系统的任务调度，实际上的调度对象是**线程**，而进程只是给线程提供了虚拟内存、全局变量等资源。

可以这么理解：

- 当进程只有一个线程时，可以认为进程就等于线程；
- 当进程拥有多个线程时，这些线程会共享相同的虚拟内存和全局变量等资源，这些资源在上下文切换的时候时不需要修改的。

线程自己的**栈和寄存器**在上下文切换时需要保存。

##### 线程上下文切换的是什么？

- 当两个线程不属于同一进程时，等同于进程的上下文切换；
- 反之，因为虚拟内存是共享的，所以在切换时，这些资源保持不变，只需要切换线程的私有数据（栈和寄存器）

#### 线程的实现

主要有三种线程的实现方式：

- **用户线程**：在用户空间实现的线程，不由内核管理
- **内核线程**：在内核中实现的线程，由内核管理

- **轻量级线程**：在内核中用来支持用户线程

用户线程和内核线程的对应关系：

- 多对一
- 一对一
- 多对多

##### 理解用户线程

⽤户线程是基于⽤户态的线程管理库来实现的，那么 **线程控制块（Thread Control Block, TCB）** 也是在库里面来实现的，对于操作系统而言是看不到这个 TCB 的，它只能看到整个进程的 PCB。

所以，用户线程的整个线程管理和调度，**操作系统不直接参与**，而是由用户级线程库函数来完成线程的管理，包括线程的创建、终止、同步和调度等。

用户级线程的模型，也就类似前⾯提到的**多对一**的关系，即多个用户线程对应同⼀个内核线程，如下图所示：

![用户线程.PNG](https://i.loli.net/2021/08/04/k8s49olwRFBWvMN.png)

用户线程的优点：

- 每个进程都需要有它私有的线程控制块（TCB）列表，⽤来跟踪记录它各个线程状态信息（PC、栈指针、寄存器），TCB 由用户级线程库函数来维护，可用于不支持线程技术的操作系统；
- ⽤户线程的切换由线程库函数来完成的，无需用户态与内核态的切换，速度特别快；

缺点：

- 由于操作系统不参与线程的调度，如果⼀个线程发起了系统调用而阻塞，那进程所包含的用户线程都不能执行了；
- 当⼀个线程开始运行后，除非它主动地交出 CPU 的使用权，否则它所在的进程当中的其他线程无法运行，因为用户态的线程没法打断当前运行中的线程，它没有这个特权，只有操作系统才有，但是用户线程不是由操作系统管理的；
- 由于时间片分配给进程，故与其他进程比，**在多线程执行时，每个线程得到的时间⽚较少**，执行会比较慢；

##### 理解内核线程

**内核线程由操作系统管理**，线程对应的 TCB 放在操作系统⾥，线程的创建、终⽌和管理都由操作系统负责。

内核线程的模型，也就类似前⾯提到的**一对一**的关系，即⼀个⽤户线程对应⼀个内核线程，如下图所示：

![内核线程.PNG](https://i.loli.net/2021/08/04/Wl8tVaQPY3rOpKA.png)

内核线程的优点：

- 在⼀个进程当中，如果某个内核线程发起系统调用而被阻塞，并不会影响其他内核线程的运行；
- **时间片分配给线程**，多线程的进程获得更多的 CPU 运行时间。

缺点：

- 线程的创建、终止和切换都是通过系统调用的方式来进行，系统开销比较大

##### 理解轻量级线程

**轻量级进程（Light-weight process，LWP）**是内核⽀持的⽤户线程，⼀个进程可有⼀个或多个 LWP，**每个 LWP 跟内核线程⼀对⼀映射**，即 LWP 都是由⼀个内核线程⽀持。

LWP与普通进程的区别在于**它只有⼀个最小的执行上下文和调度程序所需的统计信息**。

![轻量级进程.PNG](https://i.loli.net/2021/08/04/reHbaCoKt6FL1hw.png)

#### 线程间通信

- 线程通信就是当多个线程共同操作共享的资源时，互相告知自己的状态以避免资源争夺；
- 线程通信主要可以分为三种方式，分别为 **锁机制、信号量机制、信号**；

### 调度

#### 调度原则

- 原则1：发送I/O 事件致使 CPU 空闲的情况下，调度程序需要从就绪队列中选择⼀个进程来运行；
- 原则2：要提高 **系统的吞吐率**，调度程序要权衡长任务和短任务进程的运行完成数量；
- 原则3：如果进程的等待时间很长而运行时间很短，那周转时间就很长，这不是我们所期望的，调度程序应该避免这种情况发⽣；
- 原则4：就绪队列中进程的等待时间也是调度程序所需要考虑的原则；
- 原则5：对于交互式⽐较强的应⽤，响应时间也是调度程序需要考虑的原则。

#### 调度算法

##### 先来先服务 (FCFS) 调度算法

属于**非抢占式**调度算法。

每次从就绪队列选择最先进⼊队列的进程，然后⼀直运⾏，直到进程退出或被阻塞，才会继续从队列中选择第⼀个进程接着运行。

FCFS 对 **长作业** 有利，适⽤于 CPU 繁忙型作业的系统，而不适用于 I/O 繁忙型作业的系统

##### 最短作业优先 (SJF) 调度算法

优先选择 **运⾏时间最短** 的进程来运行，有助于提高系统的吞吐量。

显然对长作业不利，可能造成进程**饿死**。

##### 高响应比优先调度算法

每次进行进程调度时，先计算「响应比优先级」，然后把「响应比优先级」最高的进程投入运行，「响应比优先级」的计算公式：
$$
响应比优先级=\frac{等待时间+要求服务时间}{要求服务时间}
$$
从上面公式可以发现：

- 如果两个进程的「等待时间」相同时，「要求的服务时间」越短，「响应比」就越⾼，这样短作业的进程容易被选中运行；
- 如果两个进程「要求的服务时间」相同时，「等待时间」越长，「响应比」就越⾼，这就兼顾到了长作业进程，因为进程的响应比可以随时间等待的增加而提⾼，当其等待时间足够长时，其响应比便可以升到很⾼，从而获得运行的机会；

##### 时间片轮转调度算法

每个进程被分配⼀个时间段，称为时间片，即允许该进程在该时间段中运⾏。

- 如果时间片用完，进程还在运行，那么将会把此进程从 CPU 释放出来，并把 CPU 分配给另外⼀个进程

- 如果该进程在时间片结束前阻塞或结束，则 CPU 立即进行切换；

时间片长度设计是一个关键：

- 如果时间片设得太短会导致过多的进程上下文切换，降低了 CPU 效率；
- 如果设得太长⼜可能引起对短作业进程的响应时间变长；

一般将时间片设为 $20-50ms$。

##### 最高优先级调度算法

调度程序从就绪队列中选择最高优先级的进程运行。

进程的优先级可以分为，静态优先级和动态优先级：

- 静态优先级：创建进程时候，就已经确定了优先级了，然后整个运行时间优先级都不会变化；
- 动态优先级：根据进程的动态变化调整优先级，⽐如如果进程运⾏时间增加，则降低其优先级，如果进程等待时间（就绪队列的等待时间）增加，则提高其优先级。

可能导致优先级低的进程**饿死**。

##### 多级反馈队列调度算法

多级反馈队列（Multilevel Feedback Queue）调度算法是「时间片轮转算法」和「最高优先级算法」的综合和发展，是 **抢占式调度算法**。

- 「多级」表示有多个队列，每个队列优先级从高到低，同时优先级越高时间片越短。
- 「反馈」表示如果有新的进程加入优先级高的队列时，立刻停止当前正在运行的进程，转而去运行优先级高的队列；

![多级反馈队列.PNG](https://i.loli.net/2021/08/04/hxtIjLmHqlg23UA.png)

工作流程：

- 设置了多个队列，赋予每个队列不同的优先级，每个队列优先级从高到低，同时优先级越高，时间片越短；
- 新的进程会被放⼊到第⼀级队列的末尾，按先来先服务的原则排队等待被调度，如果在第⼀级队列规定的时间片没运行完成，则将其转入到第二级队列的末尾，以此类推，直至完成；
- 当较高优先级的队列为空，才调度较低优先级的队列中的进程运行。如果进程运行时，有新进程进⼊较高优先级的队列，则停止当前运行的进程并将其移⼊到原队列末尾，接着让较高优先级的进程运行；

### 进程间通信

每个进程的⽤户地址空间都是独⽴的，⼀般⽽⾔是不能互相访问的，但内核空间是每个进程都共享的，所以进程之间要通信必须通过内核。

![进程间通信.PNG](https://i.loli.net/2021/08/05/UfTj9cMNYIZ82xJ.png)

#### 管道

Linux 命令中，「 **| **」这个竖线就是一个 **管道**，它的功能是将前一个命令的输出，作为后一个命令的输入。

可以看出，**管道传输数据是单向的**，如果想相互通信，需要创建两个管道。

「 **| **」这种管道没有名字，称为 **匿名管道**，用完了就销毁。

管道还有另外一个类型是 **命名管道**，也被叫做 **FIFO**，因为数据是先进先出的传输方式。

通过 ***mkfifo*** 来创建，并指定管道名字：

> ***mkfifo*** myPipe

管道也是也是以文件的方式存在。

**管道通信效率低，不适合进程间频繁地交换数据**，a 进程给 b 进程传输数据，只能等待 b 进程取了数据之后 a 进程才能返回。

##### 管道如何创建

匿名管道的创建，需要通过下面这个系统调用：

``` c++
int pipe(int fd[2]);
```

这里表示创建一个匿名管道，并返回了两个描述符，一个是管道的读取段描述符 ==fd[0]==，另一个是管道的写入段描述符 ==fd[1]==。

![匿名管道.PNG](https://i.loli.net/2021/08/05/7C2USB15dZwhnJD.png)

管道，其实就是**内核里面的一串缓存**。从管道的⼀段写⼊的数据，实际上是缓存在内核中的，另⼀端读取，也就是从内核中读取这段数据。

上面两个描述符都是在⼀个进程里面，并没有起到进程间通信的作用，怎么样才能使得管道是跨过两个进程呢？

可以使⽤ ==fork== 创建⼦进程，创建的⼦进程会复制⽗进程的⽂件描述符，这样就做到了两个进程各有「 ==fd[0]== 与 ==fd[1]== 」，两个进程就可以通过各⾃的 fd 写⼊和读取同⼀个管道⽂件实现跨进程通信了。

![管道.png](https://i.loli.net/2021/08/05/rfnuhmHFjiYJSGN.png)

管道只能⼀端写⼊，另⼀端读出，所以上⾯这种模式容易造成混乱，因为⽗进程和⼦进程都可以同时写⼊，也都可以读出。那么，为了避免这种情况，通常的做法是：

- 父进程关闭读取的 ==fd[0]==，只保留写入的 ==fd[1]==;
- 子进程关闭写入的 ==fd[1]==，只保留读取的 ==fd[0]==，如下图所示：

![管道1.png](https://i.loli.net/2021/08/05/DuYncLxhA8agVpz.png)

因此，如果需要双向通信，则应该创建两个管道。

但在 shell 里面执行 ==A|B== 命令的时候，A 进程和 B 进程都是 shell 创建出来的子进程，A 和 B 之间并非父子关系，它俩的父进程是 shell。

![shell管道.PNG](https://i.loli.net/2021/08/05/MTnPYxFVdQwmA4K.png)

- 对于 **匿名管道**，它的通信范围是存在父子关系的进程。因为管道没有实体，即没有管道文件，只能通过 ==fork== 来复制父进程的 fd 文件描述符，达到通信的目的；
- 对于 **命名管道**，它可以在不相关的进程间实现通信。因为命名管道提前创建了一个类型为管道的设备文件，在进程里只要使用这个管道文件，就可以相互通信。

#### 消息队列

管道不适合进程间频繁地交换数据，**消息队列** 的通信模式可以解决这个问题。⽐如，A 进程要给 B 进程发送消息，A 进程把数据放在对应的消息队列后就可以正常返回了，B 进程需要的时候再去读取数据就可以了。

**消息队列是保存在内核中的消息链表**，在发送数据时，会分成⼀个⼀个独⽴的数据单元，也就是消息体（数据块），消息体是⽤户⾃定义的数据类型，消息的发送⽅和接收⽅要约定好消息体的数据类型，所以每个消息体都是固定⼤⼩的存储块，不像管道是⽆格式的字节流数据。如果进程从消息队列中读取了消息体，内核就会把这个消息体删除。

**消息队列⽣命周期随内核**，如果没有释放消息队列或者没有关闭操作系统，消息队列会⼀直存在，⽽前⾯提到的匿名管道的⽣命周期，是随进程的创建⽽建⽴，随进程的结束⽽销毁。

消息队列通信方式不足：

- **不适合较大数据的传输**；因为在内核中每个消息体都有⼀个最大长度的限制，同时所有队列所包含的全部消息体的总长度也是有上限；
- **存在用户态与内核态之间的数据拷贝开销**；因为进程写⼊数据到内核中的消息队列时，会发⽣从⽤户态拷⻉数据到内核态的过程，同理另⼀进程读取内核中的消息数据时，会发⽣从内核态拷⻉数据到⽤户态的过程。

#### 共享内存

**共享内存** 的方式能很好地解决用户态与内核态之间的消息拷贝过程。

共享内存的机制，就是 **拿出一块虚拟地址空间来，映射到相同的物理内存中**。这样这个进程写⼊的东⻄，另外⼀个进程⻢上就能看到了，都不需要拷⻉来拷⻉去，传来传去，⼤⼤提⾼了进程间通信的速度。

<img src="https://i.loli.net/2021/08/05/7mG2ja1hdU4FfBu.png" alt="共享内存.PNG" style="zoom: 67%;" />

#### 信号量

⽤了共享内存通信⽅式，带来新的问题，那就是如果多个进程同时修改同⼀个共享内存，就会发生冲突。

为了防⽌多进程竞争共享资源，⽽造成的数据错乱，所以需要保护机制，使得共享的资源，在任意时刻只能被⼀个进程访问。**信号量** 实现了这⼀保护机制。

信号量 **是一个整形的计数器，用于实现进程间的互斥和同步**，而不是用于缓存进程间通信的数据。

信号量表示资源的数量，控制信号量的方式有两种原子操作：

- 一个是 **P操作**，会把信号量减1，相减后如果 `信号量 < 0` ，则表明资源已被占用，进程需等待阻塞；反之，则表明还有资源可使用，进程可正常继续执行；
- 另一个操作是 **V操作**，会把信号量加1，相加后如果 `信号量 <= 0`，表明有阻塞中的进程，于是会把该进程唤醒；反之，表明当前没有阻塞中的进程。

**P操作** 用在进入共享资源前，**V操作** 用在离开共享资源之后，两个操作需要成对出现。

##### 互斥

举个例子，如果要使得两个进程互斥访问共享内存，我们可以 **初始化信号量为** ==1== 。具体过程如下：

- 进程 A 在访问共享内存前，先执⾏了 **P 操作**，由于信号量的初始值为 1，故在进程 A 执⾏ P 操作后信号量变为 **0**，表示共享资源可⽤，于是进程 A 就可以访问共享内存；
- 此时，进程 B 也想访问共享内存，执⾏了 **P 操作**，结果信号量变为了 **-1**，这就意味着临界资源已被占⽤，因此进程 B 被阻塞；
- 直到进程 A 访问完共享内存，才会执⾏ **V 操作**，使得信号量恢复为 **0**，接着就会唤醒阻塞中的线程B，使得进程 B 可以访问共享内存，最后完成共享内存的访问后，执⾏ **V 操作**，使 **信号量恢复到初始值 1**。

可以发现，**信号量初始化为** ==1== ，就代表着是 **互斥信号量**，它可以保证共享内存在任何时刻只有⼀个进程在访问，这就很好的保护了共享内存。

##### 同步

在多进程⾥，每个进程并不⼀定是顺序执⾏的，它们基本是以各⾃独⽴的、不可预知的速度向前推进，但有时候我们希望多个进程能密切合作，以实现⼀个共同的任务。

例如，进程 A 是负责⽣产数据，⽽进程 B 是负责读取数据，这两个进程是相互合作、相互依赖的，进程 A必须先⽣产了数据，进程 B 才能读取到数据，所以执⾏是有前后顺序的。

这时候，就可以⽤信号量来实现 **多进程同步** 的⽅式，我们可以 **初始化信号量为** ==0== 。

![多进程同步.PNG](https://i.loli.net/2021/08/05/4mL3RFKtAOpB8d5.png)

具体过程如下：

- 如果进程 B ⽐进程 A 先执⾏了，那么执⾏到 P 操作时，由于信号量初始值为 0，故信号量会变为-1，表示进程 A 还没⽣产数据，于是进程 B 就阻塞等待；
- 接着，当进程 A ⽣产完数据后，执⾏了 V 操作，就会使得信号量变为 0，于是就会唤醒阻塞在 P 操作的进程 B；
- 最后，进程 B 被唤醒后，意味着进程 A 已经⽣产了数据，于是进程 B 就可以正常读取数据了。

可以发现，**信号初始化为** ==0== ，就代表着是**同步信号量**，它可以保证进程 A 应在进程 B 之前执⾏。

#### 信号

对于 **异常情况** 下的⼯作模式，就需要⽤「信号」的方式来通知进程。

信号事件的来源主要有 **硬件来源**（如键盘 Cltr+C ）和 **软件来源**（如 kill 命令）。

信号是进程间通信机制中 **唯⼀的异步通信机制**，因为可以在任何时候发送信号给某⼀进程，⼀旦有信号产生，我们就有下⾯这⼏种，⽤户进程对信号的处理⽅式。

- 执行默认操作
- 捕捉信号
- 忽略信号

#### Socket

前⾯提到的管道、消息队列、共享内存、信号量和信号都是在 **同⼀台主机** 上进⾏进程间通信，那要想 **跨⽹络与不同主机** 上的进程之间通信，就需要 **Socket 通信**。

创建 Socket 的系统调用：

``` c++
int socket(int domain, int type, int protocal)
```

三个参数分别代表：

- `domain` 参数用来指定协议簇；比如 AF_INET 用于 IPV4，AF_INET6 用于 IPV6，AF_LOCAL/AF_UNIX 用于本机；
- `type` 参数用来指定通信特性；比如 SOCK_STREAM 表示的是字节流，对应 TCP；SOCK_DGRAM 表示的是数据报，对应 UDP；SOCK_RAW 表示的是原始套接字；
- `protocal` 参数原本用于指定通讯协议，现已废弃，一般写作 0。

根据创建 socket 类型的不同，通信的方式也就不同：

- 实现 TCP 字节流通信：socket 类型是 AF_INET 和 SOCK_STREAM；
- 实现 UDP 数据报通信：socket 类型是 AF_INET 和 SOCK_DGRAM；
- 实现本地进程间通信（AF_UNIX 和 AF_LOCAL 等价）：
  - 本地字节流 socket : AF_LOCAL 和 SOCK_STREAM;
  - 本地数据报 socket：AF_LOCAL 和 SOCK_DGRAM。

##### TCP socket 编程

![TCP_socket.PNG](https://i.loli.net/2021/08/05/1Gj7JDBFmz3o5YO.png)

- 服务端和客户端初始化 `socket`，得到文件描述符；
- 服务端调用 `bind`，将绑定在 IP 地址和端口；
- 服务端调用 `listen`，进行监听；
- 服务端调用 `accept`，等待客户端连接；
- 客户端调用 `connect`，向服务器端的地址和端口发起连接请求；
- 服务端 `accept` 返回用于传输的 `socket` 的文件描述符；
- 客户端调用 `write` 写入数据；服务端调用 `read` 读取数据；
- 客户端断开连接时，会调用 `close`，那么服务端 `read` 读取数据时，就会读取到 ==EOF==，待处理完数据后，服务端调用 `close`，表示连接关闭。

服务端调⽤ `accept` 时，连接成功了会返回⼀个 **已完成连接的** `socket`，后续⽤来传输数据。

即监听的 `socket` 和真正用来传送数据的 `socket`，是两个 `socket`，一个叫作 **监听** `socket`，一个叫作 **已完成连接的** `socket`。

##### UDP socket 编程

![UDP_socket.PNG](https://i.loli.net/2021/08/05/RMHaOD6ZoiUb5Ph.png)

**UDP 是没有连接的**，所以不需要三次握⼿，也就不需要像 TCP 调⽤ `listen` 和 `connect`，但是 UDP 的交互仍然需要 IP 地址和端⼝号，因此也需要 `bind`。

调⽤ `sendto` 和 `recvfrom` 时，需要传入目标主机的 IP 地址和端⼝。

##### 本地进程间通信 socket 编程

本地 `socket` 被⽤于在 **同⼀台主机上进程间通信** 的场景。

本地字节流 `socket` 和 本地数据报 `socket` 在 `bind` 的时候，不像 TCP 和 UDP 要绑定 IP 地址和端⼝，⽽是 **绑定⼀个本地⽂件**，这也就是它们之间的最⼤区别。

### 多线程同步

#### 竞争与协作

在单核 CPU 系统⾥，为了实现多个程序同时运⾏的假象，操作系统通常以时间片调度的方式，让每个进程执⾏每次执行一个时间片，时间片用完了，就切换下⼀个进程运⾏，由于这个时间⽚的时间很短，于是就造成了「并行」的现象。

如果⼀个程序只有⼀个执⾏流程，也代表它是单线程的。当然⼀个程序可以有多个执⾏流程，也就是所谓的多线程程序，**线程是调度的基本单位，进程则是资源分配的基本单位**。

所以，线程之间是可以共享进程的资源，比如代码段、堆空间、数据段、打开的文件等资源，但每个线程都有自己独⽴的栈空间。

那么问题就来了，多个线程如果竞争共享资源，如果不采取有效的措施，则会造成共享数据的混乱。

举个例子，创建两个线程，分别对共享变量 `i` 自增 1 执行 10000 次，最终 `i` 结果是多少？

答案是 **不确定**。

为了理解为什么会发⽣这种情况，我们必须了解编译器为更新计数器 `i`变量⽣成的代码序列，也就是要了解汇编指令的执⾏顺序：

<img src="https://i.loli.net/2021/08/05/4rqGTsyLb9d2cQV.png" alt="自增程序执行顺序.PNG" style="zoom:70%;" />

设想我们的线程 1 进⼊这个代码区域，它将 `i` 的值（假设此时是 50 ）从内存加载到它的寄存器中，然后它
向寄存器加 1，此时在寄存器中的 `i` 值是 51。

但此时发生了：**时钟中断**。因此，操作系统将当前正在运⾏的线程的状态保存到线程的线程控制块 TCB。

更糟的是，线程 2 被调度运行，并进⼊同⼀段代码。它也执行了第⼀条指令，从内存获取 `i` 值并将其放⼊到寄存器中，此时内存中 `i` 的值仍为 50，因此线程 2 寄存器中的 `i` 值也是 50。假设线程 2 执⾏接下来的两条指令，将寄存器中的 `i` 值 + 1，然后将寄存器中的 `i` 值保存到内存中，于是此时全局变量 `i` 值是 51。

最后，⼜发⽣⼀次 **上下⽂切换**，线程 1 恢复执行。它已经执⾏了两条汇编指令，现在准备执⾏最后⼀条指令。此时，线程 1 寄存器中的 `i` 值是51，因此，执⾏最后⼀条指令后，将值保存到内存，全局变量 `i` 的值再次被设置为 51。整个过程如下图所示：

<img src="https://i.loli.net/2021/08/05/o7Wwl9Xxvd8zC1s.png" alt="多线程自增变量.PNG" style="zoom:60%;" />

##### 互斥的概念

上⾯展示的情况称为 **竞争条件（race condition）**，当多线程相互竞争操作共享变量时，由于在执⾏过程中可能发⽣了 **上下⽂切换**，最后会得到错误的结果，因此输出的结果存在 **不确定性（indeterminate）**。

由于多线程执⾏操作共享变量的这段代码可能会导致竞争状态，因此我们将此段代码称为 **临界区（critical section）**，即 **访问共享资源的代码⽚段**，⼀定不能给多线程同时执⾏。

我们希望这段代码是 **互斥（mutualexclusion）**的，即保证 **⼀个线程在临界区执行时，其他线程应该被阻⽌进⼊临界区**。

![互斥.PNG](https://i.loli.net/2021/08/05/JsBKbHZqINmogpx.png)

##### 同步的概念

互斥解决了并发进程/线程对临界区的使⽤问题。

**同步**，则是并发进程/线程在⼀些关键点上可能需要互相等待与互通消息，这种 **相互制约的等待与互通信息** 称为进程/线程同步。

#### 互斥与同步的实现和使用

为了实现进程/线程间正确的竞争与协作，操作系统必须提供相应的措施和⽅法，主要的⽅法有两种：

- **锁**：加锁、解锁等操作；
- **信号量**：P 操作， V 操作。

这两个都可以⽅便地实现进程/线程互斥，⽽信号量⽐锁的功能更强⼀些，它还可以⽅便地实现进程/线程同步。

##### 锁

使⽤ **加锁操作** 和 **解锁操作** 可以解决并发线程/进程的互斥问题。

任何想进⼊临界区的线程，必须先执⾏加锁操作。若加锁操作顺利通过，则线程可进⼊临界区；在完成对临界资源的访问后再执⾏解锁操作，以释放该临界资源。

根据锁的实现不同，可以分为 **忙等待锁** 和 **无忙等待锁**。

###### 忙等待锁

先介绍现代 CPU 体系结构提供的 **特殊原⼦操作指令 —— 测试和置位（Test-and-Set）指令**。

``` c
int TestAndSet(int *old_ptr, int new)
{
    int old = *old_ptr;
    *old_ptr = new;
    return old;
}
```

这些代码是 **原子执行**：要么全部执行，要么都不执行，不能出现执行到⼀半的中间状态。

运⽤ Test-and-Set 指令来实现「忙等待锁」，代码如下：

``` c
typedef struct lock_t {
    int flag;
}lock_t;

void init(lock_t *lock) {
    lock->flag = 0;
}

void lock(lock_t *lock) {
    while(TestAndSet(&lock->flag, 1) == 1)
        ;
}

void unlock(lock_t *lock) {
    lock->flag = 0;
}
```

这个锁如何工作：

- 第一个场景：首先假设一个线程在运行，调用 `lock`，没有其它线程持有锁，所以 `flag = 0`。当调用 `TestAndSet(flag, 1)`方法，返回 0， 线程跳出 `while` 循环，获取锁。同时也原子地设置 `flag = 1`，标志锁已经被持有。当线程离开临界区，调用 `unlock()` 将 `flag` 清理为 0。
- 第二种场景：当某一个线程已经持有锁，即 `flag = 1`。本线程调用 `lock`，然后调用  `TestAndSet(flag, 1)`方法，返回 1。此时，只要另一个线程一直持有锁， 返回值始终为 1。本线程会一直在 `while` 循环中，即 **忙等**。当另一个线程释放锁，即 `flag = 0`，本线程调用 `TestAndSet(flag, 1)` 才会返回 0 并且原子地设置 `flag = 1`，从而获得锁，进入临界区。

很明显，当获取不到锁时，线程就会⼀直 wile 循环，不做任何事情，所以就被称为「忙等待锁」，也被称为 **⾃旋锁（spin lock）**。

###### 无等待锁

⽆等待锁顾明思议就是获取不到锁的时候，不⽤自旋。

既然不想自旋，那当没获取到锁的时候，就把当前线程放⼊到 **锁的等待队列**，然后执行调度程序，把 CPU 让给其他线程执行。

``` c
typedef struct lock_t {
    int flag;
    queue_t *q;  // 等待队列
}lock_t;

void init(lock_t *lock) {
    lock->flag = 0;
    queue_init(lock->q);
}

void lock(lock_t *lock) {
    while(TestAndSet(&lock->flag, 1) == 1) {
        // 保存现有运行线程 TCB
        // 将现在运行线程的 TCB 插入到锁的等待队列；
        // 设置该线程为等待状态；
        // 调度程序
    }
}

void unlock(lock_t *lock) {
    if(lock->q != nullptr) {
        // 移出等待队列的队头元素；
        // 将该线程的 TCB 插入到就绪队列；
        // 设置该线程为就绪状态；
    }
    
    lock->flag = 0;
}
```

##### 信号量

信号量表示 **资源的数量**，对应的变量是⼀个 **整型变量**。

###### 操作系统实现 P、V 操作

``` c
// 信号量数据结构
type struct sem_t {
    int sem;	// 资源个数
    queue_t *q; // 等待队列
}sem_t;

// 初始化信号量
void init(sem_t *s, int sem) {
    s->sem = sem;
    queue_init(s->q);
}

// P 操作
void P(sem_t *s) {
    s->sem--;
    if(s->sem < 0) {
        1. 保留调用线程 CPU 现场;
        2. 将该线程的 TCB 插入到 s 的等待队列;
        3. 设置该线程为等待状态;
        4. 执行调度程序;
    }
}

// V 操作
void V(sem_t *s) {
    s->sem++;
    if(s->sem <= 0) {
        1. 移除 s 等待队列的队头元素;
        2. 将该线程的 TCB 插入就绪队列;
        3. 设置该线程为就绪状态;
    }
}
```

###### P、V 操作使用

 信号量不仅可以实现临界区的互斥访问控制，还可以 **线程间的事件同步**。

``` c
// 信号量同步伪代码

sem_t s1 = 0;	// 表示不需要吃饭
sem_t s2 = 0;	// 表示饭还没做完

void son() {
    while(true) {
        hungry;
        V(s1); 
        P(s2);
        eating;
    }
}

void mon() {
    while(true) {
        P(s1);
        cooking;
        V(s2);
    }
}
```

##### 生产者——消费者问题

![生产者_消费者问题.PNG](https://i.loli.net/2021/08/05/SGKlEX93iWZp2ue.png)

问题描述：

- **生产者** 生成数据后，放入一个缓冲区；
- **消费者** 从缓冲区取出数据处理；
- 任何时刻，只能有 **一个** 生产者或消费者可以访问缓冲区。

代码实现：

``` c
semaphore mutex = 1;		// 互斥信号量，用于临界区的互斥访问
semaphore emptyBuffer = n;  // 表示缓冲区空槽的数量
semaphore filledBuffer = 0; // 表示缓冲区填入数据槽的数量

// 生产者
void producer() {
    while(true) {
        P(emptyBuffer);
        P(mutex);
        将生成数据放入缓冲区;
        V(mutex);
        V(filledBuffer);
    }
}

// 消费者
void customer() {
    while(true) {
        P(filledBuffer);
        P(mutex);
        从缓冲区取出数据处理;
        V(mutex);
        V(emptyBuffer);
    }
}
```

#### 经典同步问题

##### 哲学家就餐问题

问题描述：

- 5 个哲学家，围绕着一张桌子吃饭；
- 桌子上只有 5 支叉子，每两个哲学家之间放一支叉子；
- 哲学家围在⼀起先思考，思考中途饿了就会想进餐；
- 哲学家要 **两支叉子** 才能吃饭

- 吃完后，把叉子放回原处，继续思考。

如何保证哲学家的动作有序进行，而不会出现有人永远拿不到叉子？

###### 方案一

用信号量的方式解决，代码如下：

``` c
const static int N = 5;
semaphore fork[5];			// 信号量初值为1，也就是叉子的个数

void smartPerson(int i) {	// i 为哲学家编号 0-4
    while(true) {
        think();
        P(fork[i]);			// 拿左边的叉子
        P(fork[(i+1)%N]);	// 拿右边的叉子
        eat();
        V(fork[i]);			// 放下左边的叉子
        V(fork[(i+1)%N]);	// 放下右边的叉子
    }
}
```

方案一的问题：每个哲学家同时拿了左边的叉子，就会导致死锁的现象。

###### 方案二

既然「⽅案⼀」会发⽣同时竞争左边叉⼦导致死锁的现象，那么我们就在拿叉⼦前，加个互斥信号量，代码如下：

``` c++
const static int N = 5;
semaphore fork[5];			// 信号量初值为1，也就是叉子的个数
semaphore mutex;			// 互斥信号量，初值为1

void smartPerson(int i) {	// i 为哲学家编号 0-4
    while(true) {
        think();
        P(mutex);			// 进入临界区
        P(fork[i]);			// 拿左边的叉子
        P(fork[(i+1)%N]);	// 拿右边的叉子
        eat();
        V(fork[i]);			// 放下左边的叉子
        V(fork[(i+1)%N]);	// 放下右边的叉子
        V(mutex);			// 退出临界区
    }
}
```

上面程序中的互斥信号量作用在于：只要有一个哲学家准备要拿叉子时，其他哲学家都不能进餐。

方案二的问题：每次只能一个哲学家进餐。效率低。

###### 方案三

让偶数编号的哲学家「先拿左边的叉⼦后拿右边的叉⼦」，奇数编号的哲学家「先拿右边的叉⼦后拿左边的叉⼦」。

``` c
const static int N = 5;
semaphore fork[5];			// 信号量初值为1，也就是叉子的个数

void smartPerson(int i) {	// i 为哲学家编号 0-4
    while(true) {
        think();
        
        if (i%2 == 0) {
            P(fork[i]);			// 偶数先拿左边叉子
            P(fork[(i+1)%N]);	// 后拿右边叉子
        }else {
            P(fork[(i+1)%N]);	// 奇数先拿右边叉子
            P(fork[i]);			// 后拿左边叉子
        }
       
        eat();
        
        V(fork[i]);			// 放下左边的叉子
        V(fork[(i+1)%N]);	// 放下右边的叉子
    }
}
```

在 P 操作时，根据哲学家的编号不同，拿起左右两边叉⼦的顺序不同。另外，V 操作是不需要分⽀的，因为  **V 操作是不会阻塞的**。

方案三不会出现死锁，也可以两人同时进餐。

###### 方案四

⽤⼀个数组 state 来记录每⼀位哲学家在进程、思考还是饥饿状态（正在试图拿叉⼦）。

⼀个哲学家只有 **在两个邻居都没有进餐**时，才可以进⼊进餐状态。

``` c
const static int N = 5;
#define LEFT (i+N-1)%N		// i 的左邻居
#define RIGHT (i+1)%N		// i 的右邻居

enumerate state = {THINKING, HUNGRY, EATING};

int states[N];

semaphore s[5];			// 每个哲学家一个信号量，初值为0，
semaphore mutex;

void test(int i) {
    if(state[i] == HUNGRY && state[LEFT] != EATING && state[right] != EATING) {
        state[i] = EATING;		// 两把叉子到手，进餐状态
        V(s[i]);				// 通知第 i 哲学家可以进餐了
    }
}

void test_forks(int i) {
    P(mutex);				// 进入临界区
    state[i] == HUNGRY;		// 标记哲学家处于饥饿状态
    test(i);				// 尝试获取两个叉子
    V(mutex);				// 离开临界区
    P(s[i]);				// 没有叉子则阻塞，有叉子则继续正常执行
}

void put_forks(int i) {
    P(mutex);
    state[i] == THINKING;
    test(LEFT);				// 检查左边邻居哲学家是否进餐
    test(RIGHT);			// 检查右边邻居哲学家是否进餐
    V(mutex);
}

void smartPerson(int i) {	// i 为哲学家编号 0-4
    while(true) {
        think();
        take_forks(i);
        eat();
        put_forks(i);
    }
}
```

上⾯的程序使⽤了⼀个信号量数组，每个信号量对应⼀位哲学家，这样在所需的叉⼦被占⽤时，想进餐的哲学家就被阻塞。

##### 读者——写者问题

「哲学家进餐问题」对于 **互斥访问有限的竞争问题（如 I/O 设备）**⼀类的建模过程⼗分有⽤。

「读者-写者」，它为 **数据库访问** 建⽴了⼀个模型。

读者只会读取数据，不会修改数据，⽽写者即可以读也可以修改数据。

读者-写者的问题描述：

- 「读-读」允许：同⼀时刻，允许多个读者同时读；
- 「读-写」互斥：没有写者时读者才能读，没有读者时写者才能写；
- 「写-写」互斥：没有其他写者时，写者才能写。

###### 方案一

使用信号量的方式来解决：

- 信号量 `wMutex`：控制写操作的互斥信号量，初始值为 1；
- 读者计数 `rCount`：正在进行读操作的读者个数，初始值为 0；
- 信号量 `rCountMutex`：控制对 `rCount` 读者计数器的互斥修改，初始值为 1。

代码如下：

``` c
semaphore wMutex;				// 控制写操作的互斥信号量，初始值为 1
semaphore rCountMutex;
int rCount = 0;

void writer() {
    while(true) {
        P(wMutex);
        write();
        V(wMutex);
    }
}

void reader() {
    while(true) {
        P(rCountMutex);
        if (rCount == 0) {
            P(wMutex);			// 如果有写者，则阻塞写者
        }
        rCount++;
        V(rCountMutex);
        
        read();
        
        P(rCountMutex);
        rCount--;
        if (rCount == 0) {
            V(wMutex);			// 最后一个读者离开后，唤醒写者
        }
        V(rCountMutex);
    }
}
```

上⾯的这种实现，是 **读者优先** 的策略，因为只要有读者正在读的状态，后来的读者都可以直接进⼊，如果读者持续不断进⼊，则写者会处于饥饿状态。

###### 方案二

既然有读者优先策略，⾃然也有写者优先策略：

- 只要有写者准备要写⼊，写者应尽快执⾏写操作，后来的读者就必须阻塞；
- 如果有写者持续不断写⼊，则读者就处于饥饿；

在⽅案⼀的基础上新增如下变量：

- 信号量 `rMutex `：控制读者进⼊的互斥信号量，初始值为 1；
- 信号量 `wDataMutex` ：控制写者写操作的互斥信号量，初始值为 1；
- 写者计数 `wCount `：记录写者数量，初始值为 0；
- 信号量 `wCountMutex `：控制 `wCount` 互斥修改，初始值为 1。

实现代码如下：

``` c
semaphore rMutex;				// 控制读者进入的互斥信号量，初始值为 1
semaphore rCountMutex;			// 控制对 rCOunt 的互斥修改，初始值为 1

semaphore wCountMutex;			// 控制对 wCount 的互斥修改，初始值为 1
semaphore wDataMutex;			// 控制写者写操作的互斥信号量，初始值为 1

int rCount = 0;
int wCount = 0;

void writer() {
    while(true) {
        P(wCountMutex);
        if (wCount == 0) {
            P(rMutex);			// 当第一个写者进入，如果有读者则阻塞读者
        }
        wCount++;
        V(wCountMutex);
        
        P(wDataMutex);
        write();
        V(wDataMutex);
        
        P(wCountMutex);
        wCount--;
        if (wCount == 0) {
            V(rMutex);			// 最后一个写者离开了，则唤醒读者
        }
        V(wCountMutex);
    }
}

void reader() {
    while(true) {
        P(rMutex);
        P(rCountMutex);
        if (rCount == 0) {
            P(wDataMutex);		// 当第一个读者进入，如果有写者则阻塞写者
        }
        rCount++;
        V(rCountMutex);
        V(rMutex);
        
        read();
        
        P(rCountMutex);
        rCount--;
        if (rCount == 0) {
            V(wDataMutex);			// 最后一个读者离开后，唤醒写者
        }
        V(rCountMutex);
    }
}
```

这⾥ `rMutex` 的作⽤，开始有多个读者读数据，它们全部进⼊读者队列，此时来了⼀个写者，执⾏了`P(rMutex)` 之后，后续的读者由于阻塞在 `rMutex` 上，都不能再进⼊读者队列，⽽写者到来，则可以全部进⼊写者队列，因此保证了写者优先。

第⼀个写者执⾏了 `P(rMutex)` 之后，也不能⻢上开始写，必须等到所有进⼊读者队列的读者都执⾏完读操作，通过 `V(wDataMutex)` 唤醒写者的写操作。

###### 方案三

公平策略：

- 优先级相同
- 写者、读者互斥访问
- 只有一个写者访问互斥区
- 可以有多个读者同时访问临界资源

代码实现如下：

``` c
semaphore rCountMutex;
semaphore wDataMutex;
semaphore flag;
int wCount = 0;

void writer() {
    while(true) {
        P(flag);
        P(wDataMutex);
        write();
        V(wDataMutex);
       	V(flag);
    }
}

void reader() {
    while(true) {
        P(flag);
        P(rCountMutex);
        if (rCount == 0) {
            P(wDataMutex);		// 当第一个读者进入，如果有写者则阻塞写者
        }
        rCount++;
        V(rCountMutex);
        V(flag);
        
        read();
        
        P(rCountMutex);
        rCount--;
        if (rCount == 0) {
            V(wDataMutex);			// 最后一个读者离开后，唤醒写者
        }
        V(rCountMutex);
    }
}
```

对⽐⽅案⼀的读者优先策略，可以发现，读者优先中只要后续有读者到达，读者就可以进⼊读者队列， ⽽写者必须等待，直到没有读者到达。

没有读者到达会导致读者队列为空，即 `rCount==0 `，此时写者才可以进⼊临界区执⾏写操作。

这⾥ `flag` 的作⽤就是阻⽌读者的这种特殊权限（特殊权限是只要读者到达，就可以进⼊读者队列）。

比如：开始来了⼀些读者读数据，它们全部进⼊读者队列，此时来了⼀个写者，执⾏ `P(flag)` 操作，使得后续到来的读者都阻塞在 `flag` 上，不能进⼊读者队列，这会使得读者队列逐渐为空，即 `rCount` 减为 0。

这个写者也不能⽴⻢开始写（因为此时读者队列不为空），会阻塞在信号量 `wDataMutex` 上，读者队列中的读者全部读取结束后，最后⼀个读者进程执⾏ `V(wDataMutex)`，唤醒刚才的写者，写者则继续开始进⾏写操作

### 死锁

在多线程编程中，我们为了防⽌多线程竞争共享资源⽽导致数据错乱，都会在操作共享资源之前加上互斥锁。当两个线程为了保护两个不同的共享资源⽽使⽤了两个互斥锁，那么这两个互斥锁应⽤不当的时候，可能会造成 **两个线程都在等待对⽅释放锁**，在没有外⼒的作⽤下，这些线程会⼀直相互等待，就没办法继续运⾏，这种情况就是发⽣了 **死锁**。

死锁发生需同时满足以下条件：

- 互斥
- 持有并等待
- 不可剥夺
- 环路等待

#### 互斥

互斥条件是指 **多个线程不能同时使用同一个资源**。

#### 持有并等待

持有并等待条件是指 **当进程因请求资源而阻塞时，对已获得的资源保持不放**。比如，当线程 A 已经持有了资源 1，又想申请资源 2，而资源 2 已经被线程 C 持有了，所以线程 A 就会处于等待状态，但是线程 A 在等待资源 2 的同时并不会释放已经持有的资源 1。 

#### 不可剥夺

不可剥夺条件是指 **进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。**

#### 环路等待

环路等待条件是指 **在发生死锁时，必然存在一个进程--资源的环形链。**

<img src="https://i.loli.net/2021/08/06/uermQ3pStsOPHKo.png" alt="环路等待.PNG" style="zoom:70%;" />

#### 避免死锁问题发生

产生死锁的四个条件需要同时满足，因此，避免死锁问题就只需要破环其中⼀个条件就可以。

- 资源一次性分配：破坏持有并等待条件
- 可剥夺资源：当某进程获得了部分资源，但无法获取其它资源时，释放已占有的资源；破坏不可剥夺条件
- 资源有序分配法：系统给每类资源赋予一个编号，每一个进程按编号递增的顺序请求资源，释放则相反；破坏环路等待条件。

### 锁的选择和使用

#### 互斥锁与自旋锁

互斥锁和自旋锁是最基础的两种锁。

加锁的⽬的就是保证共享资源在任意时间⾥，只有⼀个线程访问，这样就可以避免多线程导致共享数据错乱的问题。

当已经有⼀个线程加锁后，其他线程加锁则就会失败，互斥锁和⾃旋锁对于加锁失败后的处理⽅式是不⼀样的：

- **互斥锁** 加锁失败后，线程会释放 CPU 给其它线程；
- **自旋锁** 加锁失败后，线程会 **忙等待**，直到拿到锁；

互斥锁加锁失败⽽阻塞的现象，是由操作系统内核实现的。当加锁失败时，内核会将线程置为「睡眠」状态，等到锁被释放后，内核会在合适的时机唤醒线程，当这个线程成功获取到锁后，于是就可以继续执行。如下图：

<img src="https://i.loli.net/2021/08/06/AY2ZSXp8VfMvOlo.png" alt="互斥锁.PNG" style="zoom:67%;" />

所以，互斥锁加锁失败时，会从用户态陷⼊到内核态，让内核帮我们切换线程，虽然简化了使用锁的难度，但是存在⼀定的性能开销成本，包括 **两次线程上下文切换的成本**。

如果锁住的代码执行时间⽐较短，那可能上下文切换的时间会比锁住代码的执⾏时间还要⻓。因此，如果你能确定被锁住的代码执行时间很短，就不应该⽤互斥锁，⽽应该选⽤⾃旋锁，否则使⽤互斥锁。

**⾃旋锁** 是通过 CPU 提供的 CAS 函数（Compare And Swap），在**用户态完成加锁和解锁操作**，不会主动产生线程上下文切换，所以相⽐互斥锁来说，会快⼀些，开销也⼩⼀些。

#### 读写锁

由 **读锁** 和 **写锁** 两部分构成，如果只读取共享数据用 **读锁** 加锁，如果要修改共享资源则用 **写锁** 加锁。

写锁是 **独占锁**，因为任何时刻只能有⼀个线程持有写锁，类似互斥锁和⾃旋锁，⽽读锁是 **共享锁**，因为读锁可以被多个线程同时持有。

读写锁可分为 **读优先锁** 和 **写优先锁**。

##### 读优先锁

当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 仍然可以成功获取读锁，最后直到读线程 A 和 C 释放读锁后，写线程 B 才可以成功获取写锁。如下图：

<img src="https://i.loli.net/2021/08/06/JzNmTPdIvChbFR7.png" alt="读写锁.PNG" style="zoom: 67%;" />

##### 写优先锁

当读线程 A 先持有了读锁，写线程 B 在获取写锁的时候，会被阻塞，并且在阻塞过程中，后续来的读线程 C 获取读锁时会失败，于是读线程 C 将被阻塞在获取读锁的操作，这样只要读线程 A 释放读锁后，写线程 B 就可以成功获取读锁。如下图：

<img src="https://i.loli.net/2021/08/06/tWaMhEzPQGUscor.png" alt="写优先锁.PNG" style="zoom:67%;" />

#### 乐观锁与悲观锁

前面提到的互斥锁、自旋锁、读写锁，都属于悲观锁。

悲观锁做事⽐较悲观，它认为多线程同时修改共享资源的概率⽐较⾼，于是很容易出现冲突，所以访问共享资源前，先要上锁。

那相反的，如果 **多线程同时修改共享资源的概率⽐较低**，就可以采⽤ **乐观锁**。

乐观锁做事⽐较乐观，它假定冲突的概率很低，它的⼯作⽅式是：**先修改** 完共享资源，**再验证** 这段时间内有没有发⽣冲突，如果没有其他线程在修改资源，那么操作完成，**如果发现有其他线程已经修改过这个资源，就放弃本次操作**。

应用场景：在线文档。

### 多线程同步编程

对于多线程程序来说，同步是指在一定的时间内只允许某一个线程访问某个资源 而在此时间内，不允许其他的线程访问该资源。可以通过 **互斥锁（ mutex ）**、**条件变量（ condition variable ）**、**读写锁（reader-writer lock ）**和 **信号量（ emphore ）**来同步资源。

### 多线程重入

各种同步方式，其实都是为了解决“函数不可重入”的问题。所谓 **可重入函数**，是指 **可以由多于一个任务并发使用，而不必担心数据错误的函数**。相反，“不可重入函数” 则是只能由一个任务所占用，除非能确保函数的互斥（或者使用信号量，或者在代码的关键部分禁用中断）。可重入函数可以在任意时刻被中断，稍后再继续运行，且不会丢失数据。可重入函数要在使用本地变量或在使用全局变量时保护自己的数据。

#### 线程安全

当多个线程访问某个类时，不管运行时环境采用何种调度方式或者这些线程将如何交替执行，并且在调用代码中不需要任何额外的同步或者协同，这个类都能表现出正确的行为，那么就称这个类是线程安全的。
